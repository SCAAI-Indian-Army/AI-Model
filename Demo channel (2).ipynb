{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    samples = np.expand_dims(face_pixels, axis=0)\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Retraining:\n",
    "    def __init__(self,path, rotation_range = 60, horizontal_flip = True):\n",
    "        from mtcnn import MTCNN\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        from keras.preprocessing.image import ImageDataGenerator\n",
    "        \n",
    "        self.datagen = ImageDataGenerator(rotation_range= rotation_range, horizontal_flip= horizontal_flip)\n",
    "        self.face_detector = MTCNN()\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.X_image = []\n",
    "        self.y_label = []\n",
    "        self.path = path\n",
    "        self.size = (160,160)\n",
    "    def load_image(self):\n",
    "        import cv2\n",
    "        import glob\n",
    "        try:\n",
    "            file_path = self.path + \"/*.*\"\n",
    "            for i in glob.glob(file_path):\n",
    "                img = cv2.imread(i)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                self.X_image.append(img)\n",
    "                label = i.split(\"/\")[-1]\n",
    "                label = label[:len(label)-9]\n",
    "                self.y_label.append(label)\n",
    "        except:\n",
    "            print(\"Invalid Path\")\n",
    "    def extract_face(self):\n",
    "        import cv2\n",
    "        X=[]\n",
    "        y=[]\n",
    "        try:\n",
    "            for i in range(len(self.X_image)):\n",
    "                img = self.X_image[i]\n",
    "                result = self.face_detector.detect_faces(img)\n",
    "                k=0\n",
    "                for k in range(len(result)):\n",
    "                    if(k >= 1):\n",
    "                        print(\"Required 1 person per image\")\n",
    "                    else:\n",
    "                        x1, y1, width, height = result[k]['box']\n",
    "                        x1, y1 = abs(x1), abs(y1)\n",
    "                        x2, y2 = x1+width, y1+height\n",
    "                        face = img[y1:y2, x1:x2]\n",
    "                        face = cv2.resize(face,self.size)\n",
    "                        X.append(face)\n",
    "                        y.append(self.y_label[i])\n",
    "            self.X_image = X\n",
    "            self.y_label = y\n",
    "        except Exception as e:\n",
    "            print(\"code failed in extract_face\")\n",
    "            print(e)\n",
    "    def face_augmentation(self, n = 7):\n",
    "        import glob\n",
    "        import os\n",
    "        import numpy as np\n",
    "        try:\n",
    "            if(os.path.isdir(\"Desktop/Kashmir Augmented Image\") == True):\n",
    "                for i in glob.glob(\"Desktop/Kashmir Augmented Image/*.*\"):\n",
    "                    os.remove(i)\n",
    "                os.rmdir(\"Desktop/Kashmir Augmented Image\")\n",
    "            self.augmentation_path = \"Desktop/Kashmir Augmented Image\" \n",
    "            os.mkdir(self.augmentation_path)\n",
    "            for i in range(len(self.X_image)):\n",
    "                img = self.X_image[i]\n",
    "                img = np.reshape(img,(1,160,160,3))\n",
    "                j=0\n",
    "                for batch in self.datagen.flow(img, batch_size=1, save_to_dir= self.augmentation_path, save_prefix = self.y_label[i], save_format = \"jpg\"):\n",
    "                    if(j >= n):\n",
    "                        break\n",
    "                    j+=1\n",
    "            return self\n",
    "        except Exception as e:\n",
    "            print(\"Code is failed in face_augmentation\")\n",
    "            print(e)\n",
    "            \n",
    "    def load_augmented_image(self):\n",
    "        import cv2\n",
    "        import glob\n",
    "        X = []\n",
    "        y_label = []\n",
    "        try:\n",
    "            for i in glob.glob(self.augmentation_path+\"/*.*\"):\n",
    "                img = cv2.imread(i)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                X.append(img)\n",
    "                y = i.split(\"/\")[-1]\n",
    "                y = y.split(\"_\")\n",
    "                y = y[0] + y[1]\n",
    "                y_label.append(y)\n",
    "            self.X_image = X\n",
    "            self.y_label = y_label\n",
    "        except Exception as e:\n",
    "            print(\"Code is failed in load_augmented_image\")\n",
    "            print(e)\n",
    "            \n",
    "    def features_to_numbers(self,path):\n",
    "        from keras.models import load_model\n",
    "        from keras.utils import np_utils\n",
    "        import pickle\n",
    "        \n",
    "        self.facenet_model = load_model(path)\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(len(self.X_image)):\n",
    "            X.append(get_embedding(self.facenet_model, self.X_image[i]))\n",
    "        y = self.encoder.fit_transform(self.y_label)\n",
    "        pickle.dump(self.encoder,open(\"Desktop/encoder\",\"wb\"))\n",
    "        self.no_classes = len(set(y))\n",
    "        y = np_utils.to_categorical(y, self.no_classes)\n",
    "        self.X_image = X\n",
    "        self.y_label = y\n",
    "    def training_NN(self, epochs = 10, path = \"Desktop/Kashmir Production/new_kashmir3.model\"):\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Dense\n",
    "        import numpy as np\n",
    "        self.nn_model = Sequential()\n",
    "        self.nn_model.add(Dense(self.no_classes*3, input_dim = 128 , activation = \"relu\"))\n",
    "        self.nn_model.add(Dense(self.no_classes*2, activation = \"relu\"))\n",
    "        self.nn_model.add(Dense(self.no_classes, activation = \"softmax\"))\n",
    "        self.nn_model.compile(loss = \"categorical_crossentropy\", optimizer= \"adam\", metrics=[\"accuracy\"])\n",
    "        print(self.nn_model.summary())\n",
    "        self.X_image = np.array(self.X_image)\n",
    "        self.y_label = np.array(self.y_label)\n",
    "        self.nn_model.fit(self.X_image, self.y_label, epochs = epochs)\n",
    "        self.nn_model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(path,model_path = \"Desktop/Kashmir Production/new_kashmir3.model\", face_net_model = \"Desktop/facenet_keras.h5/model/facenet_keras.h5\"):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from keras.models import load_model\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mtcnn import MTCNN\n",
    "    import pickle\n",
    "        \n",
    "    nn_model = load_model(model_path)\n",
    "    facenet_model = load_model(face_net_model)\n",
    "    face_detector = MTCNN()\n",
    "    encoder_file = open(\"Desktop/encoder\",\"rb\")\n",
    "    encoder = pickle.load(encoder_file)\n",
    "        \n",
    "    X_test = []\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = face_detector.detect_faces(img)\n",
    "    for k in range(len(result)):\n",
    "        x1, y1, width, height = result[k]['box']\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1+width, y1+height\n",
    "        face = img[y1:y2, x1:x2]\n",
    "        face = cv2.resize(face,(160,160))\n",
    "        X_test.append(face)\n",
    "    X_test = np.array(X_test)\n",
    "    for i in range(len(X_test)):\n",
    "        img = X_test[i]\n",
    "        img = get_embedding(facenet_model, img)\n",
    "        img = np.array(img)\n",
    "        img = np.reshape(img, (1,128))\n",
    "        y_pred = nn_model.predict(img)\n",
    "        y_pred = y_pred[0]\n",
    "        confidence = max(y_pred)\n",
    "        y_pred = np.argmax(y_pred)\n",
    "        y_pred = encoder.inverse_transform([y_pred])[0]\n",
    "        print(\"Name of Person = \",y_pred)\n",
    "        print(\"Accuracy = \",confidence*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 166 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc094933488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc094933488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc094933488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc094bd8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0958d27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_217 (Dense)            (None, 117)               15093     \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 78)                9204      \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 39)                3081      \n",
      "=================================================================\n",
      "Total params: 27,378\n",
      "Trainable params: 27,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.6819 - accuracy: 0.0705\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.4378 - accuracy: 0.1410\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2614 - accuracy: 0.2372\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.0943 - accuracy: 0.3462\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9195 - accuracy: 0.4872\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7406 - accuracy: 0.5256\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5525 - accuracy: 0.5641\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3454 - accuracy: 0.6410\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1436 - accuracy: 0.6987\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9373 - accuracy: 0.7308\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7368 - accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5475 - accuracy: 0.8013\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3803 - accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2298 - accuracy: 0.8397\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.8526\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9832 - accuracy: 0.8590\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8897 - accuracy: 0.8590\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8016 - accuracy: 0.8590\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.8782\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.9231\n",
      "INFO:tensorflow:Assets written to: Desktop/Kashmir Production/new_kashmir3.model/assets\n"
     ]
    }
   ],
   "source": [
    "a = AI_Retraining(\"Desktop/kashmir_raw_dataset 2\")\n",
    "a.load_image()  #Loading Image\n",
    "a.extract_face()    #Face Extraction\n",
    "a.face_augmentation(3)    #Face Augmentation\n",
    "a.load_augmented_image()  # Loading Augmented Image\n",
    "a.features_to_numbers(\"Desktop/facenet_keras.h5/model/facenet_keras.h5\")      #Loading Facenet Model\n",
    "a.training_NN(20)             # Loading Neural Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:5 out of the last 163 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0c7c3d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 165 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0c792d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 166 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0c76d6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0c544da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Name of Person =  Abdul GaniBhajmasta\n",
      "Accuracy =  75.22468566894531 %\n"
     ]
    }
   ],
   "source": [
    "prediction(path = \"Desktop/kashmir_raw_dataset 2/Abdul Gani_Bhajmasta_img1.jpg\")        #Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0f4dbba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0f4dbba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0f4dbba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0f4dbb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0f495d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc1259c9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0f523e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'inverse_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6eb644215141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Desktop/kashmir_raw_dataset 2/Abdul Gani_Bhajmasta_img1.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-197b408f4356>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(self, path, model_path, face_net_model)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name of Person = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'inverse_transform'"
     ]
    }
   ],
   "source": [
    "prediction(path = \"Desktop/kashmir_raw_dataset 2/Abdul Gani_Bhajmasta_img1.jpg\")        #Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
