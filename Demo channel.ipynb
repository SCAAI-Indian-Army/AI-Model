{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    samples = np.expand_dims(face_pixels, axis=0)\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Retraining:\n",
    "    def __init__(self,path, rotation_range = 60, horizontal_flip = True):\n",
    "        from mtcnn import MTCNN\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        from keras.preprocessing.image import ImageDataGenerator\n",
    "        \n",
    "        self.datagen = ImageDataGenerator(rotation_range= rotation_range, horizontal_flip= horizontal_flip)\n",
    "        self.face_detector = MTCNN()\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.X_image = []\n",
    "        self.y_label = []\n",
    "        self.path = path\n",
    "        self.size = (160,160)\n",
    "    def load_image(self):\n",
    "        import cv2\n",
    "        import glob\n",
    "        try:\n",
    "            file_path = self.path + \"/*.*\"\n",
    "            for i in glob.glob(file_path):\n",
    "                img = cv2.imread(i)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                self.X_image.append(img)\n",
    "                label = i.split(\"/\")[-1]\n",
    "                label = label[:len(label)-9]\n",
    "                self.y_label.append(label)\n",
    "        except:\n",
    "            print(\"Invalid Path\")\n",
    "    def extract_face(self):\n",
    "        import cv2\n",
    "        X=[]\n",
    "        y=[]\n",
    "        try:\n",
    "            for i in range(len(self.X_image)):\n",
    "                img = self.X_image[i]\n",
    "                result = self.face_detector.detect_faces(img)\n",
    "                k=0\n",
    "                for k in range(len(result)):\n",
    "                    if(k >= 1):\n",
    "                        print(\"Required 1 person per image\")\n",
    "                    else:\n",
    "                        x1, y1, width, height = result[k]['box']\n",
    "                        x1, y1 = abs(x1), abs(y1)\n",
    "                        x2, y2 = x1+width, y1+height\n",
    "                        face = img[y1:y2, x1:x2]\n",
    "                        face = cv2.resize(face,self.size)\n",
    "                        X.append(face)\n",
    "                        y.append(self.y_label[i])\n",
    "            self.X_image = X\n",
    "            self.y_label = y\n",
    "        except Exception as e:\n",
    "            print(\"code failed in extract_face\")\n",
    "            print(e)\n",
    "    def face_augmentation(self, n = 7):\n",
    "        import os\n",
    "        import numpy as np\n",
    "        try:\n",
    "            self.augmentation_path = \"Desktop/Kashmir Augmented Image\" \n",
    "            os.mkdir(self.augmentation_path)\n",
    "            for i in range(len(self.X_image)):\n",
    "                img = self.X_image[i]\n",
    "                img = np.reshape(img,(1,160,160,3))\n",
    "                j=0\n",
    "                for batch in self.datagen.flow(img, batch_size=1, save_to_dir= self.augmentation_path, save_prefix = self.y_label[i], save_format = \"jpg\"):\n",
    "                    if(j >= n):\n",
    "                        break\n",
    "                    j+=1\n",
    "            return self\n",
    "        except Exception as e:\n",
    "            print(\"Code is failed in face_augmentation\")\n",
    "            print(e)\n",
    "            \n",
    "    def load_augmented_image(self):\n",
    "        import cv2\n",
    "        import glob\n",
    "        X = []\n",
    "        y_label = []\n",
    "        try:\n",
    "            for i in glob.glob(self.augmentation_path+\"/*.*\"):\n",
    "                img = cv2.imread(i)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                X.append(img)\n",
    "                y = i.split(\"/\")[2]\n",
    "                y = y.split(\"_\")\n",
    "                y = y[0] + y[1]\n",
    "                y_label.append(y)\n",
    "            self.X_image = X\n",
    "            self.y_label = y_label\n",
    "        except Exception as e:\n",
    "            print(\"Code is failed in load_augmented_image\")\n",
    "            print(e)\n",
    "            \n",
    "    def features_to_numbers(self,path):\n",
    "        from keras.models import load_model\n",
    "        from keras.utils import np_utils\n",
    "        \n",
    "        self.facenet_model = load_model(path)\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(len(self.X_image)):\n",
    "            X.append(get_embedding(self.facenet_model, self.X_image[i]))\n",
    "        y = self.encoder.fit_transform(self.y_label)\n",
    "        self.no_classes = len(set(y))\n",
    "        y = np_utils.to_categorical(y, self.no_classes)\n",
    "        self.X_image = X\n",
    "        self.y_label = y\n",
    "    def training_NN(self, epochs = 10):\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Dense\n",
    "        import numpy as np\n",
    "        self.nn_model = Sequential()\n",
    "        self.nn_model.add(Dense(self.no_classes*3, input_dim = 128 , activation = \"relu\"))\n",
    "        self.nn_model.add(Dense(self.no_classes*2, activation = \"relu\"))\n",
    "        self.nn_model.add(Dense(self.no_classes, activation = \"softmax\"))\n",
    "        self.nn_model.compile(loss = \"categorical_crossentropy\", optimizer= \"adam\", metrics=[\"accuracy\"])\n",
    "        print(self.nn_model.summary())\n",
    "        self.X_image = np.array(self.X_image)\n",
    "        self.y_label = np.array(self.y_label)\n",
    "        self.nn_model.fit(self.X_image, self.y_label, epochs = epochs)\n",
    "        self.nn_model.save(\"Desktop/Kashmir Production/new_kashmir3.model\")\n",
    "    def prediction(path):\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        from keras.models import load_model\n",
    "\n",
    "        nn_model = load_model(\"Desktop/Kashmir Production/new_kashmir3.model\")\n",
    "        X_test = []\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = self.face_detector.detect_faces(img)\n",
    "        for k in range(len(result)):\n",
    "            x1, y1, width, height = result[k]['box']\n",
    "            x1, y1 = abs(x1), abs(y1)\n",
    "            x2, y2 = x1+width, y1+height\n",
    "            face = img[y1:y2, x1:x2]\n",
    "            face = cv2.resize(face,self.size)\n",
    "            X_test.append(face)\n",
    "        X_test = np.array(X_test)\n",
    "        for i in range(len(X_test)):\n",
    "            img = X_test[i]\n",
    "            img = np.reshape(img,(1,160,160,3))\n",
    "            y_pred = nn_model.predict(img)\n",
    "            y_pred = y_pred[0]\n",
    "            confidence = max(y_pred)\n",
    "            y_pred = np.argmax(y_pred)\n",
    "            y_pred = self.encoder.inverse_transform(y_pred)\n",
    "            print(y_pred, end=\" \")\n",
    "            print(confidence*100)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retraining():\n",
    "    a = AI_model(\"Desktop/kashmir_raw_dataset 2\")\n",
    "    a.load_image()\n",
    "    a.extract_face()\n",
    "    a.face_augmentation(3)\n",
    "    a.load_augmented_image()\n",
    "    a.features_to_numbers(\"Desktop/facenet_keras.h5/model/facenet_keras.h5\")\n",
    "    a.training_NN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 163 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7f03819488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 164 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7eaf6fa158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted: 'Desktop/Kashmir Augmented Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d92b51d1f519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Desktop/Kashmir Augmented Image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: 'Desktop/Kashmir Augmented Image'"
     ]
    }
   ],
   "source": [
    "class AI_pred:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "    def prediction():\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        from keras.models import load_model\n",
    "        \n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img,(160,160,3))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.array(img)\n",
    "        img = np.reshape(img, (1,160,160,3))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
